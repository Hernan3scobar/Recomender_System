{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender systems \n",
    "\n",
    "They are algorithms widely utilized for companies in e-commerce, streaming platforms, and other sectors. Their primary goal is to predict user preferences and suggest items or content that align with those preferences.\n",
    "\n",
    "Recommender systems are designed to enhance user experience by providing personalized recommendations. They leverage data from users‚Äô past interactions, such as:\n",
    "\n",
    "* Purchase History: In e-commerce, systems suggest products based on what users have previously bought or browsed.\n",
    "* Ratings: On platforms like movie or music services, recommendations are often based on the ratings users give to items.\n",
    "* Behavioral Data: This includes browsing history, search queries, and time spent on certain content.\n",
    "\n",
    "#### Methods Used\n",
    "* Collaborative Filtering: This method makes predictions based on the behavior and preferences of similar users. For example, if User A and User B have similar tastes, and User A likes a new product, the system may recommend that product to User B.\n",
    "\n",
    "        Collaborative Filtering can be also classified as:\n",
    "        Item CF\n",
    "        User CF\n",
    "        Matrix factorization\n",
    "\n",
    "* Content-Based Filtering: Recommendations are based on the attributes of items and users' past preferences. For instance, if a user frequently watches action movies, the system might suggest new action films.\n",
    "\n",
    "* Hybrid Approaches: These combine collaborative and content-based filtering to improve recommendation accuracy and mitigate the shortcomings of individual methods.\n",
    "\n",
    "#### Applications\n",
    "* E-commerce: Suggests products similar to those previously viewed or purchased.\n",
    "* Streaming Platforms: Recommends movies, shows, or music based on viewing or listening history.\n",
    "* Social Media: Curates posts or friends' suggestions based on interaction patterns.\n",
    "\n",
    "Recommender systems play a crucial role in personalizing user experiences, increasing engagement, and driving sales by predicting and catering to individual preferences.\n",
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "Collaborative Filtering (CF) is a popular recommendation algorithm that predicts user preferences based on the behavior and preferences of similar users. The core idea is that if users share similar tastes or behaviors, then items liked by one user can be recommended to another similar user.\n",
    "\n",
    "#### Because they are so popular, we can find types of collaborative filtering.\n",
    "\n",
    "* User-Based Collaborative Filtering (User CF): This approach identifies users with similar tastes to the target user. It assumes that if User A and User B have a high overlap in their preferences, they will likely share future preferences as well.\n",
    "\n",
    "We can formulate this aproch by concider a matrix $R$, this is going to be the user-item matrix where $ùëÖ_{ij}$ is the rating given by user $i$ to item $j$, the  similarity between users $u$ and $v$ is computed using cosine similarity or Pearson correlation given by:\n",
    "\n",
    "\n",
    "$Sim(u, v) = \\frac{\\sum_{i \\in I_{uv}} (R_{ui} - \\bar{R_u})(R_{vi} - \\bar{R_v})}{\\sqrt{\\sum_{i \\in I_{uv}} (R_{ui} - \\bar{R_u})^2} \\cdot \\sqrt{\\sum_{i \\in I_{uv}} (R_{vi} - \\bar{R_v})^2}}$\n",
    "\n",
    "\n",
    "where $\\bar{R_u}$ and $\\bar{R_v}$ are the average ratings of users $u$ and $v$, respectively, and $I_{uv}$ is the set of items rated by both users.\n",
    "\n",
    "* Item-Based Collaborative Filtering (Item CF): This approach identifies items similar to those the target user has rated or liked. It assumes that if items are similar, users who liked one item are likely to like similar items. If a  User A likes Item X and Item X is similar to Item Y, the system will recommend Item Y to User A.\n",
    "\n",
    "${Sim}(i, j) = \\frac{\\sum_{u \\in U_{ij}} (R_{ui} - \\bar{R_u})(R_{uj} - \\bar{R_u})}{\\sqrt{\\sum_{u \\in U_{ij}} (R_{ui} - \\bar{R_u})^2} \\cdot \\sqrt{\\sum_{u \\in U_{ij}} (R_{uj} - \\bar{R_u})^2}}\n",
    "$\n",
    "\n",
    "* Matrix Factorization: Matrix factorization techniques decompose the user-item matrix $R$  into two lower-dimensional matrices, typically referred to as \n",
    "$U$ (user features) and $V$ (item features). The product of these matrices approximates the original matrix $R$. This approach captures latent features of users and items, which helps in making predictions for missing entries in $R$. \n",
    "\n",
    "The goal is to find matrices $U$ (user matrix) and $V$ (item matrix) such that their product approximates the original matrix $R$:\n",
    "\n",
    "$R \\approx U \\cdot V^T$\n",
    "\n",
    "Here, $U$ is a matrix of size $m \\times k$ (where $m$ is the number of users and $k$ is the number of latent features), and $V$ is a matrix of size $n \\times k$ (where $n$ is the number of items). $k$ is typically much smaller than $m$ or $n$.\n",
    "\n",
    "The optimization problem can be formulated as:\n",
    "\n",
    "$\\min_{U, V} \\sum_{(i, j) \\in K} (R_{ij} - U_i \\cdot V_j^T)^2 + \\lambda (\\| U \\|^2 + \\| V \\|^2)$\n",
    "\n",
    "where $K$ is the set of observed ratings, and $\\lambda$ is a regularization parameter to prevent overfitting.\n",
    "\n",
    "Example: In Singular Value Decomposition (SVD), matrix factorization is performed as follows:\n",
    "\n",
    "$R = U \\Sigma V^T$\n",
    "\n",
    "where $\\Sigma$ is a diagonal matrix of singular values, and $U$ and $V$ contain the singular vectors.\n",
    "\n",
    "Matrix factorization methods are powerful because they can discover hidden patterns in data and are often more effective in capturing complex relationships compared to simpler user-based or item-based methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering \n",
    "\n",
    " This an advanced recommendation algorithm that leverages neural networks to model user-item interactions. Unlike traditional collaborative filtering methods, which rely on linear models, NCF uses deep learning techniques to capture complex patterns in the data. Here is a detailed explanation with the mathematical formulation:\n",
    "\n",
    "### Basic Concepts\n",
    "\n",
    "**User-Item Matrix**: Let $R$ be the user-item interaction matrix, where $R_{ij}$ represents the interaction (e.g., rating, click, purchase) between user $i$ and item $j$.\n",
    "\n",
    "**Latent Vectors**:\n",
    "   - $\\mathbf{p}_i$: Latent vector for user $i$ (user embedding).\n",
    "   - $\\mathbf{q}_j$: Latent vector for item $j$ (item embedding).\n",
    "\n",
    "\n",
    "   In **Generalized Matrix Factorization (GMF)**, the interaction between user $i$ and item $j$ is modeled as:\n",
    "   $$\n",
    "   \\hat{y}_{ij} = \\mathbf{p}_i^T \\mathbf{q}_j\n",
    "   $$\n",
    "   where $\\mathbf{p}_i$ and $\\mathbf{q}_j$ are learned via optimization.\n",
    "\n",
    "\n",
    "NCF extends GMF by replacing the dot product with a neural network that can model non-linear interactions between users and items. The key components are:\n",
    "**Embedding Layers**:\n",
    "   Users and items are mapped to latent vectors (tensors) using embedding layers:\n",
    "   $$\n",
    "   \\mathbf{p}_i = \\text{Embedding}_U(i)\n",
    "   $$\n",
    "   $$\n",
    "   \\mathbf{q}_j = \\text{Embedding}_I(j)\n",
    "   $$\n",
    "\n",
    "**Concatenation Layer**:\n",
    "   The user and item embeddings are concatenated to form a joint representation:\n",
    "   $$\n",
    "   \\mathbf{z}_{ij} = [\\mathbf{p}_i; \\mathbf{q}_j]\n",
    "   $$\n",
    "\n",
    "**Neural Network Layers**:\n",
    "   The concatenated vector $\\mathbf{z}_{ij}$ is fed into a multi-layer perceptron (MLP) to model the interaction:\n",
    "   $$\n",
    "   \\mathbf{h}_1 = f_1(\\mathbf{W}_1 \\mathbf{z}_{ij} + \\mathbf{b}_1)\n",
    "   $$\n",
    "   $$\n",
    "   \\mathbf{h}_2 = f_2(\\mathbf{W}_2 \\mathbf{h}_1 + \\mathbf{b}_2)\n",
    "   $$\n",
    "   $$\n",
    "   \\vdots\n",
    "   $$\n",
    "   $$\n",
    "   \\mathbf{h}_L = f_L(\\mathbf{W}_L \\mathbf{h}_{L-1} + \\mathbf{b}_L)\n",
    "   $$\n",
    "   where $\\mathbf{W}_l$ and $\\mathbf{b}_l$ are the weights and biases of the $l$-th layer, and $f_l$ is the activation function (e.g., ReLU).\n",
    "\n",
    "**Prediction Layer**:\n",
    "   The output of the final MLP layer is passed through a prediction layer to produce the predicted interaction:\n",
    "   $$\n",
    "   \\hat{y}_{ij} = \\sigma(\\mathbf{h}_L)\n",
    "   $$\n",
    "   where $\\sigma$ is an activation function, typically a sigmoid for binary interactions.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "The model is trained using a loss function that measures the discrepancy between the predicted interactions $\\hat{y}_{ij}$ and the actual interactions $y_{ij}$. For binary interactions, a common choice is the binary cross-entropy loss:\n",
    "$$\n",
    "\\mathcal{L} = - \\sum_{(i,j) \\in K} \\left( y_{ij} \\log(\\hat{y}_{ij}) + (1 - y_{ij}) \\log(1 - \\hat{y}_{ij}) \\right)\n",
    "$$\n",
    "where $K$ is the set of observed interactions.\n",
    "\n",
    "### Regularization\n",
    "\n",
    "To prevent overfitting, regularization terms are added to the loss function. This can include $L^{2}$ regularization on the weights and biases of the neural network:\n",
    "$$\n",
    "\\mathcal{L}_{\\text{reg}} = \\lambda \\left( \\|\\mathbf{W}\\|^2 + \\|\\mathbf{b}\\|^2 \\right)\n",
    "$$\n",
    "where $\\lambda$ is the regularization parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding RecSys\n",
    "\n",
    "In what follows, I will develop a model for movie recommendation based on a dataset from MovieLens. This dataset contains approximately 33,000,000 ratings and 2,000,000 tag applications applied to 86,000 movies by 330,975 users. It includes tag genome data with 14 million relevance scores across 1,100 tags. The dataset was last updated in September 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"ml-latest-small/ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(main_path)\n",
    "#df_big = pd.read_csv(\"ml-latest/ratings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931\n",
       "5       1       70     3.0  964982400\n",
       "6       1      101     5.0  964980868\n",
       "7       1      110     4.0  964982176\n",
       "8       1      151     5.0  964984041\n",
       "9       1      157     5.0  964984100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 610, Unique movies: 9724\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique users: {df.userId.nunique()}, Unique movies: {df.movieId.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 282977, Unique movies: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# unique_movies = df_big['movieId'].unique()\n",
    "# sampled_movies = np.random.choice(unique_movies, size=10000, replace=False)\n",
    "\n",
    "# sampled_df = df_big[df_big['movieId'].isin(sampled_movies)]\n",
    "\n",
    "# print(f\"Unique users: {sampled_df.userId.nunique()}, Unique movies: {sampled_df.movieId.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following class implements the Dataset module from PyTorch to create a custom tensor dataset for movie recommendations.\n",
    "# The dataset consists of user IDs, movie IDs, and ratings, where each entry represents a user-movie pair with a rating.\n",
    "\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self,users,movies,ratings) -> None:\n",
    "        super().__init__()\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        users = self.users[idx]\n",
    "        movies = self.movies[idx]\n",
    "        ratings = self.ratings[idx]\n",
    "        \n",
    "        users_tensor = torch.tensor(users, dtype=torch.long)\n",
    "        movies_tensor = torch.tensor(movies, dtype=torch.long)\n",
    "        ratings_tensor = torch.tensor(ratings, dtype=torch.long)\n",
    "\n",
    "        return users_tensor,movies_tensor,ratings_tensor\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class, derived from nn.Module, implements a neural network model for a recommendation system.\n",
    "# The model is designed to embed user and movie IDs into tensors and then predict the rating for a given user-movie pair.\n",
    "# The key components of the model are:\n",
    "# - Embedding Layers: Maps user and movie IDs to latent vectors (dense tensors), capturing latent features of users and items.\n",
    "# - Concatenation Layer: Joins the user and movie embeddings to form a combined representation of user-item interactions.\n",
    "# - Neural Network Layers: A linear layer that takes the concatenated embeddings to predict the rating, mimicking the final step \n",
    "#   of NCF models, explain before\n",
    "\n",
    "\n",
    "class RecSysMoviesLens(nn.Module):\n",
    "    def __init__(self,n_users,n_movies,n_embbedings=32) -> None:\n",
    "        super().__init__()\n",
    "        self.user_embeding = nn.Embedding(n_users,n_embbedings)\n",
    "        self.movies_embeding = nn.Embedding(n_movies,n_embbedings)\n",
    "        self.out = nn.Linear(n_embbedings*2,1)\n",
    "        \n",
    "    def forward(self,users,movies):\n",
    "        users_embedding = self.user_embeding(users)\n",
    "        movies_embedding = self.movies_embeding(movies)\n",
    "        x = torch.cat([users_embedding,movies_embedding],dim=1)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice that the  Users and Movies  Ids start from 1, when working with tensors in PyTorch, especially # in the context of embedding layers or other \n",
    " indexing operations, having user and movie IDs starting from 1 (instead of 0) can cause problems like the indexing in PyTorch, like most programming \n",
    " languages and libraries, uses zero-based indexing. This means that the first element in a tensor or array is accessed with index 0. The Embedding layers\n",
    " are other source of possible error, when one uses an embedding layer (torch.nn.Embedding), the input indices should range from 0 to $n‚àí1$ (where $n$ is \n",
    " the number of unique items). If the indices start from 1, the embedding layer will not correctly map these indices unless the input is adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       0        0     4.0  964982703\n",
       "1       0        2     4.0  964981247\n",
       "2       0        5     4.0  964982224\n",
       "3       0       43     5.0  964983815\n",
       "4       0       46     5.0  964982931\n",
       "5       0       62     3.0  964982400\n",
       "6       0       89     5.0  964980868\n",
       "7       0       97     4.0  964982176\n",
       "8       0      124     5.0  964984041\n",
       "9       0      130     5.0  964984100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movies = preprocessing.LabelEncoder()\n",
    "\n",
    "df[\"userId\"]=lbl_user.fit_transform(df[\"userId\"])\n",
    "df[\"movieId\"]=lbl_movies.fit_transform(df[\"movieId\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Test splip, this is easyli prepared whit skleaarn\n",
    "\n",
    "df_train, df_test  = model_selection.train_test_split(df,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MovieDataset instances for the train and test data set\n",
    "train_dataset = MovieDataset(\n",
    "    users=df_train.userId.values,\n",
    "    movies=df_train.movieId.values,\n",
    "    ratings=df_train.rating.values,    \n",
    ")\n",
    "\n",
    "test_dataset = MovieDataset(\n",
    "    users=df_test.userId.values,\n",
    "    movies=df_test.movieId.values,\n",
    "    ratings=df_test.rating.values,    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now will create a DataLoader\n",
    "\n",
    "bs = 4\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=bs,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=bs,\n",
    "    shuffle=True,\n",
    "    num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the instance of our model, RecSysMoviesLens\n",
    "\n",
    "model = RecSysMoviesLens(\n",
    "    n_users=len(lbl_user.classes_),\n",
    "    n_movies=len(lbl_movies.classes_) \n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "creiteria = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_epoch = 1\n",
    "\n",
    "# model.train()\n",
    "# for epoch_i in range(N_epoch):\n",
    "#     for users, movies, ratings in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         y_pred = model(users,movies)\n",
    "#         y_true = ratings.unsqueeze(dim=1).to(torch.float32)\n",
    "#         loss = creiteria(y_pred,y_true)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move the model to the gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "# \n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# training\n",
    "N_epoch = 1\n",
    "model.train()\n",
    "for epoch_i in range(N_epoch):\n",
    "    for users, movies, ratings in train_loader:\n",
    "        users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(users, movies)\n",
    "        y_true = ratings.unsqueeze(dim=1).to(torch.float32)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_trues = []\n",
    "\n",
    "model.eval()  \n",
    "with torch.no_grad():  #\n",
    "    for users, movies, ratings in test_loader:\n",
    "        users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "        \n",
    "        y_pred = model(users, movies).squeeze().detach().cpu().numpy().tolist()\n",
    "        y_true = ratings.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "        y_preds.append(y_pred)\n",
    "        y_trues.append(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.9263240689654494\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mse = mean_squared_error(y_trues, y_preds)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.980396270751953"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "user_movie_test = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():  #\n",
    "    for users, movies, ratings in test_loader:\n",
    "        users, movies, ratings = users.to(device), movies.to(device), ratings.to(device)\n",
    "        y_pred = model(users, movies)\n",
    "\n",
    "        for i in range(len(users)):\n",
    "            user_id = users[i].item()\n",
    "            movie_id = movies[i].item()\n",
    "            pred_rating = y_pred[i][0].item()\n",
    "            true_rating = ratings[i].item()\n",
    "            prediction_error = abs(pred_rating - true_rating)\n",
    "            \n",
    "             # Append a tuple with (predicted rating, true rating, movie ID, prediction error)\n",
    "            user_movie_test[user_id].append((pred_rating, true_rating, movie_id, prediction_error))\n",
    "            #print(f\"User: {user_id}, Movie: {movie_id}, Prediction: {pred_rating}, True: {true_rating}, Error: {prediction_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to store precisions, recalls, and recommendations\n",
    "precisions = {}\n",
    "recalls = {}\n",
    "recommendations = {}\n",
    "\n",
    "# Parameters\n",
    "k = 10\n",
    "thres = 3.5\n",
    "\n",
    "# Iterate over each user and their ratings\n",
    "for uid, user_ratings in user_movie_test.items():\n",
    "    # Sort user ratings by predicted rating in descending order\n",
    "    user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Count the number of relevant items (true ratings >= thres)\n",
    "    n_rel = sum((rating_true >= thres) for (_, rating_true, _, _) in user_ratings)\n",
    "\n",
    "    # Count the number of recommended items that are predicted as relevant and within the top k\n",
    "    n_rec_k = sum((rating_pred >= thres) for (rating_pred, _, _, _) in user_ratings[:k])\n",
    "\n",
    "    # Count the number of recommended items that are relevant (true rating >= thres) and predicted as relevant (pred rating >= thres)\n",
    "    n_rel_and_rec_k = sum(\n",
    "        ((rating_true >= thres) and (rating_pred >= thres))\n",
    "        for (rating_pred, rating_true, _, _) in user_ratings[:k]\n",
    "    )\n",
    "\n",
    "    # Store recommendations (Top k) for the user\n",
    "    recommendations[uid] = [(movie_id, rating_pred, rating_true) for (rating_pred, rating_true, movie_id, _) in user_ratings[:k]]\n",
    "\n",
    "    # # Print intermediate results for each user\n",
    "    # print(f\"User ID: {uid}\")\n",
    "    # print(f\"  Number of Relevant Items: {n_rel}\")\n",
    "    # print(f\"  Number of Recommended Items (Top {k}): {n_rec_k}\")\n",
    "    # print(f\"  Number of Relevant and Recommended Items: {n_rel_and_rec_k}\")\n",
    "\n",
    "    precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "    recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for uid in precisions:\n",
    "    print(f\"User ID: {uid} - Precision: {precisions[uid]:.2f}, Recall: {recalls[uid]:.2f}\")\n",
    "\n",
    "# Show recommendations for each user\n",
    "print(\"\\nRecommendations:\")\n",
    "for uid, recs in recommendations.items():\n",
    "    print(f\"User ID: {uid} - Recommendations: {recs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision @ 10: 0.62\n",
      "Average Recall @ 10: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print average Precision and Recall across all users\n",
    "average_precision = sum(precisions.values()) / len(precisions) if precisions else 0\n",
    "average_recall = sum(recalls.values()) / len(recalls) if recalls else 0\n",
    "\n",
    "print(f\"Average Precision @ {k}: {average_precision:.2f}\")\n",
    "print(f\"Average Recall @ {k}: {average_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_df = pd.read_csv(\"ml-latest-small/links.csv\")\n",
    "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
    "tags_df = pd.read_csv(\"ml-latest-small/tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 1\n",
      "  Movie: Wit (2001), IMDb ID: 243664, Predicted Rating: 3.0, True Rating: 4.0, Tags: cancer\n",
      "  Movie: Hamburger Hill (1987), IMDb ID: 93137, Predicted Rating: 3.3, True Rating: 3.0, Tags: No Tags\n",
      "  Movie: Door in the Floor, The (2004), IMDb ID: 348593, Predicted Rating: 3.3, True Rating: 3.0, Tags: No Tags\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to display recommendations for a specific user\n",
    "def display_recommendations_for_user(user_id, recommendations, movies_df, link_df, tags_df):\n",
    "    if user_id not in recommendations:\n",
    "        print(f\"No recommendations found for User ID: {user_id}\")\n",
    "        return\n",
    "    \n",
    "    recs = recommendations[user_id]\n",
    "    \n",
    "    recs_df = pd.DataFrame(recs, columns=['movieId', 'predicted_rating', 'true_rating'])\n",
    "    \n",
    "    merged_df = pd.merge(recs_df, movies_df, on='movieId')\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, link_df, on='movieId', how='left')\n",
    "    \n",
    "    merged_df = pd.merge(merged_df, tags_df, on='movieId', how='left')\n",
    "    \n",
    "    merged_df = merged_df.groupby(['movieId', 'title', 'imdbId', 'predicted_rating', 'true_rating'])['tag'].apply(lambda x: ', '.join(x.dropna()) if not x.dropna().empty else 'No Tags').reset_index()\n",
    "    \n",
    "    print(f\"User ID: {user_id}\")\n",
    "    for _, row in merged_df.iterrows():\n",
    "        print(f\"  Movie: {row['title']}, IMDb ID: {row['imdbId']}, Predicted Rating: {row['predicted_rating']:.1f}, True Rating: {row['true_rating']:.1f}, Tags: {row['tag']}\")\n",
    "\n",
    "display_recommendations_for_user(1, recommendations, movies_df, link_df, tags_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
